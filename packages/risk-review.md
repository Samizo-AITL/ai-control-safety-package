# AI Control Risk Review

## Overview
A design-level review to determine whether an AI / LLM-based control concept
is safe to deploy, conditionally acceptable, or should be stopped.

This review focuses on **architecture and responsibility**, not tuning or optimization.

---

## What we review

- Location of AI / LLM (real-time loop or not)
- Existence of stop, fallback, and manual override paths
- Supervisory logic (FSM or equivalent)
- Failure modes and responsibility clarity
- Long-term operation and degradation assumptions

---

## What you get

- **Go / Conditional Go / No-Go** judgment
- Key risk points clearly identified
- Recommended next actions (if any)
- 1–2 page written summary

---

## Typical use cases

- Before introducing AI / LLM-based control
- When management requests “AI adoption”
- When safety responsibility is unclear

---

## Engagement

- Duration: 1–2 hours discussion + document review
- Output: Written summary (PDF or Markdown)
- Fee guideline: **JPY 50,000 – 100,000**

This review is architecture-focused and does not include implementation.
